scenario: incident-summary-demo
agent_mode: llm
tools_enabled:
  - read_file
  - search_knowledge_base
coordination_pattern: sequential
memory_limit: 10
max_steps: 3
stop_signals: ["done", "完成"]
max_elapsed_sec: 20  # Optional cumulative tool time limit (seconds)
graph_template: "mypkg.graphs:incident_summary"  # Optional custom graph builder (module:function)
llm_config:
  provider: openai
  model: gpt-3.5-turbo-0125
  # api_key: set via OPENAI_API_KEY
shared_context:
  severity: "SEV-2"
  audience: "SRE + Eng Mgmt"
initial_instructions:
  - "阅读 incident.md 和 timeline.md，提炼根因、影响范围、已采取措施、待办事项；生成一份 150 字内的事件摘要和 3 条后续行动。"
files:
  incident.md: |
    Incident: API latency spike
    Service: api-gateway
    Impact: 10:00-10:15 UTC, p95 latency +300%, ~5% requests timed out
    Detected by: SLO alert (latency > 800ms)
    Status: mitigated
  timeline.md: |
    09:55 UTC - Deploy v1.2.3 with new auth middleware
    10:02 UTC - Latency alert fired (p95 > 800ms)
    10:05 UTC - Rolled back to v1.2.2; latency improved
    10:08 UTC - Identified high CPU due to JWT verification loop
    10:12 UTC - Cached JWKS keys; CPU normalized
    10:15 UTC - Alert cleared
notes:
  - 150 字内摘要，后跟 3 条行动项（监控/回归测试/变更守卫等）。
  - 输出用中文，行动项用有序列表。
agents:
  - name: summarizer
    mode: llm
    system_prompt: |
      你是事件响应摘要官，产出面向 SRE/管理层的中文简报。
      要求：精炼描述时间段、影响、根因、已做措施；再给 3 条下一步行动，按优先级排序。
      输出格式：<=150 字摘要 + 有序列表行动项。
    tools_allowed: [read_file, search_knowledge_base]
